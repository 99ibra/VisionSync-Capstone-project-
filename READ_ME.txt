1. calibration_images.py

Left cam and right cam pictures are taken here while holding a paper with chessboard pattern for calibration.

Images are saved in the images folder.
_________________________________________________

2. stereovision_calibration.py

Here we specify the number of squares on the chessboard pattern(vertically and horizontally)

Calibration will be performed where points will be mapped onto the corners of the squares inside the chessboard. 

Rectification is then performed which further modifies the matrix that was generated by the calibration.

Running this code will create an xml file called stereoMap.xml where essential and fundamental matrix of the left camera's x and y axis, and the right camera's x and y axis is stored. 
_________________________________________________

3. stereovision.py

Here the stereoMap.xml file will be called and the video feed will be undistorted and then rectified.

Then we create a disparity map/depth map by block matching which is done by stereoSGBM.

Calibration must be perfect inorder for the depth map and the undistorted&rectified images to come out right(we cannot proceed until we get a good calibration)
__________________________________________________

4.epipolarGeo.py 

This is optional(just for checking if the matched points line up between a left and right image example)

Here we take one left and right image from the images folder and rename them left.png and right.png, then perform block matching. The result is a plot diagram with epipolar lines drawn and similar points matched between both images.

__________________________________________________

5. objectDet.py     (ignore this)

This uses yolov8 object detection

and btw this does use the COCO dataset to label the object detected(just found out about it)
__________________________________________________

The next step is to use the yoloV8 and obtain the coordinate of the bounding box generated from left and right video feed. The pixel will be used along with details of the physical camera(focal length, distance between both cameras len's center)

_________________________________________________

6. depthEstimationWithLabels.py

This has the code that performs object detection and distance estimation. 

Distance obtained might be off by few cm(we have to tweak the depth formula or get better camera calibration)

A line is drawn in the middle to detect whether an object is on the left or right. 

Warning label is displayed the bounding box if an object is within a certain range along with an audio warning alerting the user from which side the object is approaching.


depthEstimationNoLabels.py is the same except for no text to speech and left-right indicator.



_________________________________________________

requirement :::: to run any of these code you'll need two cameras(except epipolarGeo.py)


